{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/Chapter07/Detectron2_Chapter07_Pixel_Means_and_STD.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XS3qK692JBai"
   },
   "source": [
    "# Chapter 07 - Pixel Means and Standard Deviations\n",
    "## The dataset\n",
    "Should execute the Notebook titled \"Data Processing\" first to process the dataset or run the following code to download the processed dataset from GitHub repository of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projappl/project_2006327/Detectron/datasets/2024\n"
     ]
    }
   ],
   "source": [
    "%cd /projappl/project_2006327/Detectron/datasets/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkePsvrIgOvk"
   },
   "source": [
    "## Preparing a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_7KE9jhErqDQ"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Some configurations\n",
    "name_ds = \"coco_data\"\n",
    "af = \"_annotations.coco.json\"\n",
    "img_dir = name_ds + \"/train/\"\n",
    "json_file_train = name_ds + \"/train/\" + af\n",
    "batch_size = 64\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f00mNlIaCJvN"
   },
   "outputs": [],
   "source": [
    "class LumoDataset(Dataset):\n",
    "  def __init__(self, \n",
    "                data,\n",
    "                img_dir=\"\",\n",
    "                transform = None):\n",
    "    self.data = data\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "      \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    file_name  = os.path.join(self.img_dir, \n",
    "                              self.data[idx]['file_name'])\n",
    "    image = cv2.imread(file_name)\n",
    "    if self.transform is not None:\n",
    "        image = self.transform(image = image)['image']\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DRMp2gQskB3S"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "image_size = 640\n",
    "augs = A.Compose([\n",
    "    A.Resize(height = image_size, width = image_size),\n",
    "    ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTSVuLkw-wy8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(json_file_train) as f:\n",
    "  ds = json.load(f)['images']\n",
    "\n",
    "tds = LumoDataset(ds, img_dir=img_dir, transform=augs)\n",
    "image_loader = DataLoader(tds, \n",
    "                          batch_size  = batch_size, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = num_workers,\n",
    "                          pin_memory  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znN7KM0Go80D"
   },
   "source": [
    "# Calculate running means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9gW7h5YvqNts"
   },
   "outputs": [],
   "source": [
    "def broad_cast(x, image_size, channel):\n",
    "  y = torch.broadcast_to(x, (image_size**2, channel))\n",
    "  z = y.reshape(image_size, image_size, 3)\n",
    "  return torch.moveaxis(z, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oCAzgHOOTuG2"
   },
   "outputs": [],
   "source": [
    "class RunningStats:\n",
    "  def __init__(self):\n",
    "    self.n = 0\n",
    "    self.mean = 0\n",
    "    self.ssd = 0 \n",
    "    \n",
    "  def push(self, x):\n",
    "    # start\n",
    "    dims = [0, 2, 3]\n",
    "    count = 1\n",
    "    for dim in dims:\n",
    "      count *= x.shape[dim]\n",
    "    image_size = x.shape[-1]\n",
    "    channel = x.shape[1]\n",
    "    if self.n == 0:\n",
    "      # start\n",
    "      new_mean = x.sum(axis=dims)/count\n",
    "      new_ssd = ((\n",
    "          x - broad_cast(\n",
    "                new_mean, \n",
    "                image_size, \n",
    "                channel\n",
    "                ))**2).sum(axis=dims)\n",
    "      new_count = count\n",
    "    else:\n",
    "      # old\n",
    "      old_count = self.n\n",
    "      old_mean = self.mean\n",
    "      old_ssd = self.ssd\n",
    "      old_sum = old_mean * old_count      \n",
    "      # new\n",
    "      new_count = self.n + count\n",
    "      new_sum = old_sum + x.sum(axis=dims)\n",
    "      new_mean = new_sum/(self.n + count)\n",
    "      \n",
    "      old_ssd_new_mean = (\n",
    "          old_ssd  \n",
    "          + 2*old_mean*old_sum\n",
    "          - old_count*(old_mean)**2\n",
    "          - 2*new_mean*old_sum\n",
    "          + old_count*(new_mean)**2\n",
    "          )\n",
    "      \n",
    "      new_ssd = (\n",
    "          old_ssd_new_mean + \n",
    "          (\n",
    "              (x - broad_cast(new_mean, \n",
    "                           image_size, \n",
    "                           channel))**2\n",
    "           ).sum(axis=dims))\n",
    "    # release results\n",
    "    self.mean = new_mean\n",
    "    self.ssd = new_ssd\n",
    "    self.n = new_count\n",
    "    self.std = torch.sqrt(new_ssd/(new_count-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbSv5KAfjZ_x",
    "outputId": "8bc8f0b4-12e1-40a7-8b23-ba9c1111e118"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [01:10<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([ 43.5997,  66.6202, 108.2177])\n",
      "tensor([21.9314, 26.4536, 38.3975])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rs = RunningStats()\n",
    "for inputs in tqdm(image_loader):\n",
    "  rs.push(inputs)\n",
    "\n",
    "print()\n",
    "print(rs.mean)\n",
    "print(rs.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je55QFbIH45g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyORj3iAEbjyIPQImu0caRhn",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
